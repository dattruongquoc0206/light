{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6483f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13b43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                                                                                       Non-Null Count  Dtype  \n",
      "---  ------                                                                                                       --------------  -----  \n",
      " 0   CLIENTNUM                                                                                                    10127 non-null  int64  \n",
      " 1   Attrition_Flag                                                                                               10127 non-null  object \n",
      " 2   Customer_Age                                                                                                 10127 non-null  int64  \n",
      " 3   Gender                                                                                                       10127 non-null  object \n",
      " 4   Dependent_count                                                                                              10127 non-null  int64  \n",
      " 5   Education_Level                                                                                              10127 non-null  object \n",
      " 6   Marital_Status                                                                                               10127 non-null  object \n",
      " 7   Income_Category                                                                                              10127 non-null  object \n",
      " 8   Card_Category                                                                                                10127 non-null  object \n",
      " 9   Months_on_book                                                                                               10127 non-null  int64  \n",
      " 10  Total_Relationship_Count                                                                                     10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon                                                                                       10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon                                                                                        10127 non-null  int64  \n",
      " 13  Credit_Limit                                                                                                 10127 non-null  float64\n",
      " 14  Total_Revolving_Bal                                                                                          10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy                                                                                              10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1                                                                                         10127 non-null  float64\n",
      " 17  Total_Trans_Amt                                                                                              10127 non-null  int64  \n",
      " 18  Total_Trans_Ct                                                                                               10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1                                                                                          10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio                                                                                        10127 non-null  float64\n",
      " 21  Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  10127 non-null  float64\n",
      " 22  Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  10127 non-null  float64\n",
      "dtypes: float64(7), int64(10), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Bank.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96edfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 21 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CLIENTNUM                 10127 non-null  int64  \n",
      " 1   Attrition_Flag            10127 non-null  object \n",
      " 2   Customer_Age              10127 non-null  int64  \n",
      " 3   Gender                    10127 non-null  object \n",
      " 4   Dependent_count           10127 non-null  int64  \n",
      " 5   Education_Level           10127 non-null  object \n",
      " 6   Marital_Status            10127 non-null  object \n",
      " 7   Income_Category           10127 non-null  object \n",
      " 8   Card_Category             10127 non-null  object \n",
      " 9   Months_on_book            10127 non-null  int64  \n",
      " 10  Total_Relationship_Count  10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon    10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon     10127 non-null  int64  \n",
      " 13  Credit_Limit              10127 non-null  float64\n",
      " 14  Total_Revolving_Bal       10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy           10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n",
      " 17  Total_Trans_Amt           10127 non-null  int64  \n",
      " 18  Total_Trans_Ct            10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio     10127 non-null  float64\n",
      "dtypes: float64(5), int64(10), object(6)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=df.columns[-2:], axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4197c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d70ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attrition_Flag'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88495f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.3,  random_state=42, shuffle=True, stratify=df[df.columns[1]])\n",
    "test_df, val_df = train_test_split(temp_df, test_size=1/3, random_state=42, shuffle=True, stratify=temp_df[temp_df.columns[1]])\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4ecced",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d15080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Attrition_Flag', 'Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n",
      "Numerical columns: ['CLIENTNUM', 'Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\n"
     ]
    }
   ],
   "source": [
    "cate_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", cate_columns)\n",
    "num_columns = train_df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "print(\"Numerical columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b1849f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MaxAbsScaler, LabelEncoder\n",
    "import pickle as pkl\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7036eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing_train(df, cate_columns, num_columns):\n",
    "\n",
    "    \"\"\" Preprocess the training data by encoding categorical features, scaling numerical features, and saving the encoders, scaler.\"\"\"    \n",
    "    cols = {}\n",
    "    df_temp = df.copy(deep = True)\n",
    "\n",
    "    X_train = df_temp.drop(columns=df_temp.iloc[:,0:2], axis=1, inplace=False)\n",
    "    y_train = df_temp.iloc[:, 1]\n",
    "    cate_columns = [col for col in cate_columns if col in X_train.columns]\n",
    "    num_columns = [col for col in num_columns if col in X_train.columns]\n",
    "    # Ensure the output directory exists    \n",
    "    output_dir = Path(\"models\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Label Encoding for target column                   \n",
    "    le = LabelEncoder()     \n",
    "    y_encoded = le.fit_transform(y_train)\n",
    "    # Save the label encoder\n",
    "    file_path = output_dir / \"label_encoder.pkl\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(le, f)\n",
    "\n",
    "    # 2. One-Hot Encoding for categorical columns\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    cate_encoded = ohe.fit_transform(X_train[cate_columns])\n",
    "    print(type(cate_encoded))\n",
    "    file_path = output_dir / \"ohe.pkl\"\n",
    "    # Save the OneHotEncoder    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(ohe, f)\n",
    "\n",
    "    # 3. MaxAbsScaler for numerical columns\n",
    "    scaler = MaxAbsScaler()\n",
    "    num_scaled = scaler.fit_transform(X_train[num_columns])\n",
    "    print(type(num_scaled))\n",
    "    file_path = output_dir / \"scaler.pkl\"\n",
    "    # Save the MaxAbsScaler\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(scaler, f)\n",
    "    # 4. concatenate the processed features\n",
    "    # Convert the encoded categorical features and scaled numerical features back to DataFrame\n",
    "    X_train_processed = pd.concat([pd.DataFrame(cate_encoded.toarray(), columns= ohe.get_feature_names_out(cate_columns)), pd.DataFrame(num_scaled, columns=num_columns)], axis=1)\n",
    "    cols['cate_columns'] = ohe.get_feature_names_out(cate_columns).tolist()\n",
    "    cols['num_columns'] = num_columns\n",
    "    cols['target_column'] = y_train.name\n",
    "    # Save the column names\n",
    "    cols_file_path = output_dir / \"columns.json\"    \n",
    "    with open(cols_file_path, 'w') as f:\n",
    "        json.dump(cols, f)\n",
    "    return X_train_processed, y_encoded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddc95df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Education_Level_College</th>\n",
       "      <th>Education_Level_Doctorate</th>\n",
       "      <th>Education_Level_Graduate</th>\n",
       "      <th>Education_Level_High School</th>\n",
       "      <th>Education_Level_Post-Graduate</th>\n",
       "      <th>Education_Level_Uneducated</th>\n",
       "      <th>Education_Level_Unknown</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Income_Category_$120K +</th>\n",
       "      <th>Income_Category_$40K - $60K</th>\n",
       "      <th>Income_Category_$60K - $80K</th>\n",
       "      <th>Income_Category_$80K - $120K</th>\n",
       "      <th>Income_Category_Less than $40K</th>\n",
       "      <th>Income_Category_Unknown</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.104589</td>\n",
       "      <td>0.617402</td>\n",
       "      <td>0.059567</td>\n",
       "      <td>0.147483</td>\n",
       "      <td>0.119887</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>0.086250</td>\n",
       "      <td>0.430430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.130998</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.309353</td>\n",
       "      <td>0.108373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.079239</td>\n",
       "      <td>0.702821</td>\n",
       "      <td>0.027987</td>\n",
       "      <td>0.431263</td>\n",
       "      <td>0.178857</td>\n",
       "      <td>0.510791</td>\n",
       "      <td>0.272193</td>\n",
       "      <td>0.647648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.353691</td>\n",
       "      <td>0.786651</td>\n",
       "      <td>0.296326</td>\n",
       "      <td>0.181336</td>\n",
       "      <td>0.076228</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>0.173341</td>\n",
       "      <td>0.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.078196</td>\n",
       "      <td>0.962257</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.227554</td>\n",
       "      <td>0.140608</td>\n",
       "      <td>0.309353</td>\n",
       "      <td>0.121255</td>\n",
       "      <td>0.897898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender_F  Gender_M  Education_Level_College  Education_Level_Doctorate  \\\n",
       "0       0.0       1.0                      0.0                        0.0   \n",
       "1       1.0       0.0                      0.0                        0.0   \n",
       "2       1.0       0.0                      0.0                        0.0   \n",
       "3       0.0       1.0                      0.0                        0.0   \n",
       "4       0.0       1.0                      0.0                        0.0   \n",
       "\n",
       "   Education_Level_Graduate  Education_Level_High School  \\\n",
       "0                       1.0                          0.0   \n",
       "1                       0.0                          0.0   \n",
       "2                       0.0                          0.0   \n",
       "3                       1.0                          0.0   \n",
       "4                       0.0                          0.0   \n",
       "\n",
       "   Education_Level_Post-Graduate  Education_Level_Uneducated  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         1.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         1.0   \n",
       "\n",
       "   Education_Level_Unknown  Marital_Status_Divorced  Marital_Status_Married  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      1.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     1.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   Marital_Status_Single  Marital_Status_Unknown  Income_Category_$120K +  \\\n",
       "0                    1.0                     0.0                      0.0   \n",
       "1                    1.0                     0.0                      0.0   \n",
       "2                    1.0                     0.0                      0.0   \n",
       "3                    0.0                     0.0                      0.0   \n",
       "4                    1.0                     0.0                      0.0   \n",
       "\n",
       "   Income_Category_$40K - $60K  Income_Category_$60K - $80K  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          1.0                          0.0   \n",
       "\n",
       "   Income_Category_$80K - $120K  Income_Category_Less than $40K  \\\n",
       "0                           1.0                             0.0   \n",
       "1                           0.0                             1.0   \n",
       "2                           0.0                             0.0   \n",
       "3                           1.0                             0.0   \n",
       "4                           0.0                             0.0   \n",
       "\n",
       "   Income_Category_Unknown  Card_Category_Blue  Card_Category_Gold  \\\n",
       "0                      0.0                 1.0                 0.0   \n",
       "1                      0.0                 1.0                 0.0   \n",
       "2                      1.0                 1.0                 0.0   \n",
       "3                      0.0                 1.0                 0.0   \n",
       "4                      0.0                 1.0                 0.0   \n",
       "\n",
       "   Card_Category_Platinum  Card_Category_Silver  Customer_Age  \\\n",
       "0                     0.0                   0.0      0.698630   \n",
       "1                     0.0                   0.0      0.684932   \n",
       "2                     0.0                   0.0      0.452055   \n",
       "3                     0.0                   0.0      0.780822   \n",
       "4                     0.0                   0.0      0.808219   \n",
       "\n",
       "   Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0              0.6        0.642857                  1.000000   \n",
       "1              0.8        0.642857                  0.333333   \n",
       "2              0.0        0.642857                  1.000000   \n",
       "3              0.4        0.714286                  0.500000   \n",
       "4              0.4        0.946429                  0.666667   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                0.500000               0.500000      0.104589   \n",
       "1                0.333333               0.500000      0.071764   \n",
       "2                0.166667               0.500000      0.079239   \n",
       "3                0.333333               0.500000      0.353691   \n",
       "4                0.833333               0.666667      0.078196   \n",
       "\n",
       "   Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0             0.617402         0.059567              0.147483   \n",
       "1             0.000000         0.071764              0.130998   \n",
       "2             0.702821         0.027987              0.431263   \n",
       "3             0.786651         0.296326              0.181336   \n",
       "4             0.962257         0.008025              0.227554   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0         0.119887        0.244604             0.086250               0.430430  \n",
       "1         0.110203        0.309353             0.108373               0.000000  \n",
       "2         0.178857        0.510791             0.272193               0.647648  \n",
       "3         0.076228        0.244604             0.173341               0.162162  \n",
       "4         0.140608        0.309353             0.121255               0.897898  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed, y_encoded = data_preprocessing_train(train_df, cate_columns, num_columns)\n",
    "X_train_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ce6a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14e8d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(model_name=None):\n",
    "    \"\"\"Load a pickle file.\"\"\"\n",
    "    folder_path = Path(\"models\") \n",
    "    file_path = folder_path / model_name\n",
    "    if not file_path.exists():\n",
    "        print(f\"Model file {file_path} does not exist.\")\n",
    "        return None \n",
    "    else:\n",
    "        print(f\"Loading model from {file_path}\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dee08b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_val():\n",
    "\n",
    "    val_df = pd.read_csv('val.csv')\n",
    "    val_df_temp = val_df.copy(deep=True)\n",
    "\n",
    "    cate_columns = val_df_temp.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    cate_columns_processed = json.load(open('models/columns.json', 'r'))['cate_columns']\n",
    "    num_columns = json.load(open('models/columns.json', 'r'))['num_columns']\n",
    "    cols = json.load(open('models/columns.json', 'r'))  \n",
    "\n",
    "    le = load_pickle(\"label_encoder.pkl\")\n",
    "    ohe = load_pickle(\"ohe.pkl\")        \n",
    "    scaler = load_pickle(\"scaler.pkl\")\n",
    "    if le is None or ohe is None or scaler is None:\n",
    "        print(\"Error loading preprocessing models.\")\n",
    "        return None, None   \n",
    "    else:\n",
    "        # Preprocess the validation data\n",
    "        X_val = val_df_temp.drop(columns=val_df_temp.iloc[:,0:2], axis=1, inplace=False)\n",
    "        y_val = val_df_temp.iloc[:, 1]\n",
    "        # Ensure the columns are in the same order as during training   \n",
    "        cate_columns = [col for col in cate_columns if col in X_val.columns]\n",
    "        num_columns = [col for col in num_columns if col in X_val.columns]\n",
    "        # 1. Label Encoding for target column\n",
    "        y_val_encoded = le.transform(y_val) \n",
    "        # 2. One-Hot Encoding for categorical columns\n",
    "        cate_encoded = ohe.transform(X_val[cate_columns])\n",
    "        if cate_columns_processed != ohe.get_feature_names_out(cate_columns).tolist():\n",
    "            print(\"Warning: Categorical columns in validation data do not match training data.\")\n",
    "            return None, None\n",
    "        else:\n",
    "            # 3. MaxAbsScaler for numerical columns\n",
    "            num_scaled = scaler.transform(X_val[num_columns])\n",
    "            # 4. concatenate the processed features\n",
    "            X_val_processed = pd.concat([pd.DataFrame(cate_encoded.toarray(), columns= ohe.get_feature_names_out(cate_columns)), pd.DataFrame(num_scaled, columns=num_columns)], axis=1)\n",
    "            return X_val_processed, y_val_encoded\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5286f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models\\label_encoder.pkl\n",
      "Loading model from models\\ohe.pkl\n",
      "Loading model from models\\scaler.pkl\n",
      "Confusion Matrix:\n",
      "[[150  13]\n",
      " [ 16 834]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "   Accuracy  Precision    Recall  F1 Score\n",
      "0  0.971372   0.944133  0.950711  0.947383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tqdcr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:19:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_processed\n",
    "y_train = y_encoded\n",
    "X_val_processed, y_val_encoded = process_val()\n",
    "X_val = X_val_processed\n",
    "y_val = y_val_encoded\n",
    "\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "prec = precision_score(y_val, y_pred, average='macro')  # dùng macro nếu có nhiều class\n",
    "rec = recall_score(y_val, y_pred, average='macro')\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "# In ma trận nhầm lẫn\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "# In các chỉ số đánh giá\n",
    "metrics_df = pd.DataFrame([[acc, prec, rec, f1]], columns= [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(metrics_df)\n",
    "folder_path = Path(\"models\")\n",
    "file_path = folder_path / \"model.pkl\"   \n",
    "if not file_path.exists():\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(model, f)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "file_path = folder_path / \"metrics.json\"\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(metrics_df.T.to_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83986a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attrition_Flag'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae0422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=df.columns[1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682f2e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CLIENTNUM', 'Customer_Age', 'Gender', 'Dependent_count',\n",
       "       'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category',\n",
       "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2489f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_json('test_r.json', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70597cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
